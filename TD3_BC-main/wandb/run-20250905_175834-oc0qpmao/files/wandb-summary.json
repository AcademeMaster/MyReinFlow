{"episode/reward": -294.76049551504514, "episode/length": 100, "episode/number": 218, "training/total_timesteps": 21800, "training/buffer_size": 21800, "_timestamp": 1757066493.2836766, "_runtime": 178.9791977405548, "_step": 17136, "evaluation/reward": -342.3187222878842, "evaluation/episode": 215, "training/critic_loss": 4.327639579772949, "training/timestep": 21876, "training/lambda": 0.01, "training/actor_loss": 87.86021423339844, "training/q_value": -87.86021423339844}